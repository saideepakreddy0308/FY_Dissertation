{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9304936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to Load Data\n",
    "def load_data(sector, ticker, start_date, end_date):\n",
    "    file_path = f\"ETF_Data/raw_etf_data/{sector}_{ticker}_{start_date}_to_{end_date}.csv\"\n",
    "    print(f\"Trying to load {file_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Main code execution\n",
    "if __name__ == \"__main\":\n",
    "    print(f\"Current working directory: {os.getcwd()}\")  # Print the current working directory\n",
    "    \n",
    "    start_date = \"2017-01-01\"\n",
    "    end_date = \"2022-12-31\"\n",
    "    \n",
    "    sectors_tickers = {\n",
    "        \"Commodities\": [\"GLD\", \"SLV\", \"PPLT\", \"PALL\",\"UNG\"],\n",
    "        \"Agriculture\": [\"CORN\", \"SOYB\", \"WEAT\"],\n",
    "        \"Crude Oil\": [\"USO\", \"BNO\"],\n",
    "        \"Technology\": [\"QQQ\", \"SMH\", \"HACK\",\"SKYY\",\"BOTZ\"],\n",
    "        \"Finance\": [\"XLF\",\"KBE\", \"KRE\", \"KIE\"],\n",
    "        \"Healthcare\": [\"XLV\", \"XBI\", \"PJP\",\"IHI\"],\n",
    "        \"Market Benchmark\": [\"SPY\"]\n",
    "        # Add more sectors and their tickers here\n",
    "    }\n",
    "    \n",
    "    for sector, tickers in sectors_tickers.items():\n",
    "        print(f\"Processing data for sector: {sector}\")\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            print(f\"  Processing data for ticker: {ticker}...\")\n",
    "            \n",
    "            # Load Data\n",
    "            df = load_data(sector, ticker, start_date, end_date)\n",
    "            \n",
    "            # Data Cleaning\n",
    "\n",
    "            #  Only proceed if df is not None\n",
    "            if df is not None:\n",
    "                # Date-Time Formatting\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df.set_index('Date', inplace=True)\n",
    "                \n",
    "                # Reindex to Daily frequency and interpolate\n",
    "                all_days = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "                df = df.reindex(all_days)\n",
    "                df.interpolate(method='linear', inplace=True)\n",
    "                \n",
    "                # For example: Handling Missing Values\n",
    "                if df.isnull().any().any():\n",
    "                    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "                # Handling Outliers\n",
    "                z_scores = (df - df.mean()) / df.std()\n",
    "                outliers = (z_scores > 3).any(axis=1)\n",
    "                df = df[~outliers]\n",
    "                \n",
    "                # Data Transformation\n",
    "                \n",
    "                # Numerical Transformations: Log Returns\n",
    "                df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "                \n",
    "                # Daily Returns\n",
    "                df['daily_return'] = (df['Close'] / df['Close'].shift(1)) - 1\n",
    "                \n",
    "                # Volatility\n",
    "                df['volatility'] = df['daily_return'].rolling(window=21).std() * np.sqrt(252)\n",
    "                \n",
    "                # Momentum\n",
    "                df['momentum'] = df['Close'] / df['Close'].rolling(window=90).mean() - 1\n",
    "                \n",
    "                # Categorical Data: Direction\n",
    "                df['Direction'] = np.where(df['log_return'] > 0, 1, 0)\n",
    "                \n",
    "                # Date-Time Formatting\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                \n",
    "                # Data Resampling: Weekly Average\n",
    "                weekly_data = df.resample('W', on='Date').mean()\n",
    "                \n",
    "                # Feature Engineering: Moving Averages\n",
    "                df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "                df['MA_100'] = df['Close'].rolling(window=100).mean()\n",
    "                df['MA_200'] = df['Close'].rolling(window=200).mean()\n",
    "                \n",
    "                # Remove first year data to start from \"2018-01-01\"\n",
    "                df = df[df['Date'] >= \"2017-12-25\"]\n",
    "                \n",
    "                # Saving pre-processed DataFrame for further steps\n",
    "                save_path = f\"ETF_Data/processed_etf_data/preprocessed_{sector}_{ticker}_2018-01-01_to_{end_date}.csv\"\n",
    "                df.to_csv(save_path, index=False)\n",
    "                print(f\"  Saved processed data to {save_path}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"No data available for sector: {sector}, ticker: {ticker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a27eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to Load Data\n",
    "def load_data(sector, ticker, start_date, end_date):\n",
    "    file_path = f\"ETF_Data/data/raw_etf_data/{sector}_{ticker}_{start_date}_to_{end_date}.csv\"\n",
    "    print(f\"Trying to load {file_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Main code execution\n",
    "if __name__ == \"__main\":\n",
    "    print(f\"Current working directory: {os.getcwd()}\")  # Print the current working directory\n",
    "    \n",
    "    start_date = \"2017-01-01\"\n",
    "    end_date = \"2022-12-31\"\n",
    "    \n",
    "    sectors_tickers = {\n",
    "        \"Commodities\": [\"GLD\", \"SLV\", \"PPLT\", \"PALL\",\"UNG\"],\n",
    "        \"Agriculture\": [\"CORN\", \"SOYB\", \"WEAT\"],\n",
    "        \"Crude Oil\": [\"USO\", \"BNO\"],\n",
    "        \"Technology\": [\"QQQ\", \"SMH\", \"HACK\",\"SKYY\",\"BOTZ\"],\n",
    "        \"Finance\": [\"XLF\",\"KBE\", \"KRE\", \"KIE\"],\n",
    "        \"Healthcare\": [\"XLV\", \"XBI\", \"PJP\",\"IHI\"],\n",
    "        \"Market Benchmark\": [\"SPY\"]\n",
    "        # Add more sectors and their tickers here\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for sector, tickers in sectors_tickers.items():\n",
    "        print(f\"Processing data for sector: {sector}\")\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            print(f\"  Processing data for ticker: {ticker}...\")\n",
    "            \n",
    "            # Load Data\n",
    "            df = load_data(sector, ticker, start_date, end_date)\n",
    "            \n",
    "            # Data Cleaning\n",
    "            \n",
    "            # Handling Missing Values\n",
    "            if df.isnull().any().any():\n",
    "                df.fillna(method='ffill', inplace=True)\n",
    "            \n",
    "            # Handling Outliers\n",
    "            z_scores = (df - df.mean()) / df.std()\n",
    "            outliers = (z_scores > 3).any(axis=1)\n",
    "            df = df[~outliers]\n",
    "            \n",
    "            # Data Transformation\n",
    "            \n",
    "            # Numerical Transformations: Log Returns\n",
    "            df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "            \n",
    "            # Daily Returns\n",
    "            df['daily_return'] = (df['Close'] / df['Close'].shift(1)) - 1\n",
    "            \n",
    "            # Volatility\n",
    "            df['volatility'] = df['daily_return'].rolling(window=21).std() * np.sqrt(252)\n",
    "            \n",
    "            # Momentum\n",
    "            df['momentum'] = df['Close'] / df['Close'].rolling(window=90).mean() - 1\n",
    "            \n",
    "            # Categorical Data: Direction\n",
    "            df['Direction'] = np.where(df['log_return'] > 0, 1, 0)\n",
    "            \n",
    "            # Date-Time Formatting\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # Data Resampling: Weekly Average\n",
    "            weekly_data = df.resample('W', on='Date').mean()\n",
    "            \n",
    "            # Feature Engineering: Moving Averages\n",
    "            df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "            df['MA_100'] = df['Close'].rolling(window=100).mean()\n",
    "            df['MA_200'] = df['Close'].rolling(window=200).mean()\n",
    "            \n",
    "            # Remove first year data to start from \"2018-01-01\"\n",
    "            df = df[df['Date'] >= \"2018-01-01\"]\n",
    "            \n",
    "            # Saving pre-processed DataFrame for further steps\n",
    "            save_path = f\"ETF_Data/data/raw_etf_data/preprocessed_{sector}_{ticker}_2018-01-01_to_{end_date}.csv\"\n",
    "            df.to_csv(save_path, index=False)\n",
    "            print(f\"  Saved processed data to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48911df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\saide\\Documents\\Final_Year_Dissertation\\ETF_Data\\scripts\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbac197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
