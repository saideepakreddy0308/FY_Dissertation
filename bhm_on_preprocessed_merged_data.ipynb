{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e55aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='hierarchical_model.log', level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    logging.info('Loading data...')\n",
    "    # Your preprocessed merged data\n",
    "    df = pd.read_csv('etf_data/preprocessed_merged_data.csv')\n",
    "    etf_groups = df['ETF'].unique()\n",
    "    n_etfs = len(etf_groups)\n",
    "\n",
    "    # Map ETFs to indices for hierarchical modeling\n",
    "    df['ETF_idx'] = df['ETF'].map({etf: i for i, etf in enumerate(etf_groups)})\n",
    "\n",
    "    logging.info('Preparing data...')\n",
    "    selected_features = [col for col in df.columns if col not in [\n",
    "        'ETF', 'Close', 'Date', 'ETF_idx']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[selected_features], df['Close'], test_size=0.2, stratify=df['ETF_idx'])\n",
    "\n",
    "    etf_idx_train = df.loc[X_train.index, 'ETF_idx']\n",
    "    etf_idx_test = df.loc[X_test.index, 'ETF_idx']\n",
    "\n",
    "    logging.info('Building hierarchical model...')\n",
    "    with pm.Model() as hierarchical_model:\n",
    "        \n",
    "        # Convert DataFrame to tensor\n",
    "        X_train_tensor = at.as_tensor_variable(X_train.values.astype('float64'))\n",
    "\n",
    "        # Hyperpriors\n",
    "        mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=1)\n",
    "        sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=1)\n",
    "\n",
    "        mu_beta = pm.Normal('mu_beta', mu=0, sigma=1)\n",
    "        sigma_beta = pm.HalfNormal('sigma_beta', sigma=1)\n",
    "\n",
    "        # ETF-level random intercepts\n",
    "        alpha = pm.Normal('alpha', mu=mu_alpha,\n",
    "                          sigma=sigma_alpha, shape=n_etfs)\n",
    "\n",
    "        # Fixed slopes for each predictor\n",
    "        beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta,\n",
    "                         shape=len(selected_features))\n",
    "\n",
    "        # Model error\n",
    "        sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "        # Expected value\n",
    "        mu = alpha[etf_idx_train] + at.dot(X_train_tensor, beta)\n",
    "\n",
    "        # Data likelihood\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "        # Sampling\n",
    "        trace = pm.sample(500, tune=200, target_accept=0.9, cores=4)\n",
    "\n",
    "        # WAIC for model comparison\n",
    "        waic = pm.waic(trace, scale='deviance')\n",
    "        logging.info(f'WAIC: {waic.waic}')\n",
    "\n",
    "    logging.info('Model trained.')\n",
    "\n",
    "    # Posterior Predictive Checks\n",
    "    ppc = pm.sample_posterior_predictive(\n",
    "        trace, model=hierarchical_model, samples=500)\n",
    "    y_pred = ppc['y_obs'].mean(axis=0)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    logging.info(f'Mean Squared Error: {mse}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'An error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26ce785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='hierarchical_model.log', level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    logging.info('Loading data...')\n",
    "    \n",
    "    # Assuming your preprocessed merged data is stored in 'preprocessed_merged_data.csv'\n",
    "    df = pd.read_csv('etf_data/preprocessed_merged_data.csv')  \n",
    "    etf_groups = df['ETF'].unique()\n",
    "    n_etfs = len(etf_groups)\n",
    "\n",
    "    # Map ETFs to indices for hierarchical modeling\n",
    "    df['ETF_idx'] = df['ETF'].map({etf: i for i, etf in enumerate(etf_groups)})\n",
    "\n",
    "    logging.info('Preparing data...')\n",
    "    \n",
    "    # Here, 'Close' is considered as the target variable. You can change it as per your specific goal.\n",
    "    selected_features = [col for col in df.columns if col not in ['Date', 'ETF', 'ETF_idx', 'Close']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[selected_features], df['Close'], test_size=0.2, stratify=df['ETF_idx'])\n",
    "\n",
    "    etf_idx_train = df.loc[X_train.index, 'ETF_idx']\n",
    "    etf_idx_test = df.loc[X_test.index, 'ETF_idx']\n",
    "\n",
    "    logging.info('Building hierarchical model...')\n",
    "    with pm.Model() as hierarchical_model:\n",
    "        \n",
    "        # Hyperpriors\n",
    "        mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=1)\n",
    "        sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=1)\n",
    "        \n",
    "        mu_beta = pm.Normal('mu_beta', mu=0, sigma=1)\n",
    "        sigma_beta = pm.HalfNormal('sigma_beta', sigma=1)\n",
    "        \n",
    "        # ETF-level random intercepts\n",
    "        alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_etfs)\n",
    "        \n",
    "        # Fixed slopes for each predictor\n",
    "        beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta, shape=len(selected_features))\n",
    "        \n",
    "        # Model error\n",
    "        sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "        \n",
    "        # Convert DataFrame to tensor\n",
    "        X_train_tensor = at.as_tensor_variable(X_train.values.astype('float64'))\n",
    "        \n",
    "        # Expected value\n",
    "        mu = alpha[etf_idx_train] + at.dot(X_train_tensor, beta)\n",
    "        \n",
    "        # Data likelihood\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "        # Sampling\n",
    "        trace = pm.sample(500, tune=200, target_accept=0.9, cores=4)\n",
    "        \n",
    "        # WAIC for model comparison\n",
    "        waic = pm.waic(trace, scale='deviance')\n",
    "        logging.info(f'WAIC: {waic.waic}')\n",
    "\n",
    "    logging.info('Model trained.')\n",
    "    \n",
    "    # Posterior Predictive Checks\n",
    "    ppc = pm.sample_posterior_predictive(trace, model=hierarchical_model, samples=500)\n",
    "    y_pred = ppc['y_obs'].mean(axis=0)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    logging.info(f'Mean Squared Error: {mse}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'An error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code without using aesara so beta,tensor variable error coming up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cf1f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saide\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\multipledispatch\\dispatcher.py:27: AmbiguityWarning: \n",
      "Ambiguities exist in dispatched function _unify\n",
      "\n",
      "The following signatures may result in ambiguous behavior:\n",
      "\t[ConstrainedVar, Var, Mapping], [object, ConstrainedVar, Mapping]\n",
      "\t[object, ConstrainedVar, Mapping], [ConstrainedVar, Var, Mapping]\n",
      "\t[object, ConstrainedVar, Mapping], [ConstrainedVar, object, Mapping]\n",
      "\t[ConstrainedVar, object, Mapping], [object, ConstrainedVar, Mapping]\n",
      "\n",
      "\n",
      "Consider making the following additions:\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "  warn(warning_text(dispatcher.name, ambiguities), AmbiguityWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='hierarchical_model.log', level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    logging.info('Loading data...')\n",
    "    df = pd.read_csv('etf_data/preprocessed_merged_data.csv')\n",
    "    etf_groups = df['ETF'].unique()\n",
    "    n_etfs = len(etf_groups)\n",
    "\n",
    "    df['ETF_idx'] = df['ETF'].astype('category').cat.codes\n",
    "\n",
    "    logging.info('Preparing data...')\n",
    "    selected_features = [col for col in df.columns if col not in ['Date', 'ETF', 'Close', 'ETF_idx']]\n",
    "    X = df[selected_features].values\n",
    "    y = df['Close'].values\n",
    "    etf_idx = df['ETF_idx'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test, etf_idx_train, etf_idx_test = train_test_split(X, y, etf_idx, test_size=0.2, stratify=etf_idx)\n",
    "\n",
    "    logging.info('Building hierarchical model...')\n",
    "    with pm.Model() as hierarchical_model:\n",
    "\n",
    "        # Hyperpriors\n",
    "        mu_alpha = pm.Normal('mu_alpha', mu=0., sigma=1)\n",
    "        sigma_alpha = pm.HalfCauchy('sigma_alpha', beta=1)\n",
    "        \n",
    "        mu_beta = pm.Normal('mu_beta', mu=0., sigma=1)\n",
    "        sigma_beta = pm.HalfCauchy('sigma_beta', beta=1)\n",
    "        \n",
    "        # ETF-level random intercepts\n",
    "        alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_etfs)\n",
    "        \n",
    "        # Fixed effects.\n",
    "        beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta, shape=(X_train.shape[1],))\n",
    "        \n",
    "        # Model error\n",
    "        sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "        \n",
    "        # Expected value\n",
    "        mu = alpha[etf_idx_train] + pm.math.dot(X_train, beta)\n",
    "        \n",
    "        # Data likelihood\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "        trace = pm.sample(500, tune=200, cores=4, target_accept=0.9)\n",
    "\n",
    "        waic = pm.waic(trace, scale='deviance')\n",
    "        logging.info(f'WAIC: {waic.waic}')\n",
    "\n",
    "    logging.info('Model trained.')\n",
    "    \n",
    "    # Posterior Predictive Checks\n",
    "    with hierarchical_model:\n",
    "        ppc = pm.sample_posterior_predictive(trace, samples=500)\n",
    "    y_pred = ppc['y_obs'].mean(axis=0)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    logging.info(f'Mean Squared Error: {mse}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'An error occurred: {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e509fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Above code works well and few rows do have null values/empty places in preprocessed merged data, updated code is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59992fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='hierarchical_model.log', level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    logging.info('Loading data...')\n",
    "    df = pd.read_csv('etf_data/preprocessed_merged_data.csv')\n",
    "    df.dropna(inplace=True)  # Remove NaN values\n",
    "    \n",
    "    etf_groups = df['ETF'].unique()\n",
    "    n_etfs = len(etf_groups)\n",
    "\n",
    "    df['ETF_idx'] = df['ETF'].astype('category').cat.codes\n",
    "\n",
    "    logging.info('Preparing data...')\n",
    "    selected_features = [col for col in df.columns if col not in ['Date', 'ETF', 'Close', 'ETF_idx']]\n",
    "    X = df[selected_features].values\n",
    "    y = df['Close'].values\n",
    "    etf_idx = df['ETF_idx'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test, etf_idx_train, etf_idx_test = train_test_split(X, y, etf_idx, test_size=0.2, stratify=etf_idx)\n",
    "\n",
    "    logging.info('Building hierarchical model...')\n",
    "    with pm.Model() as hierarchical_model:\n",
    "\n",
    "        # Hyperpriors\n",
    "        mu_alpha = pm.Normal('mu_alpha', mu=0., sigma=1)\n",
    "        sigma_alpha = pm.HalfCauchy('sigma_alpha', beta=1)\n",
    "        \n",
    "        mu_beta = pm.Normal('mu_beta', mu=0., sigma=1)\n",
    "        sigma_beta = pm.HalfCauchy('sigma_beta', beta=1)\n",
    "        \n",
    "        # ETF-level random intercepts\n",
    "        alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_etfs)\n",
    "        \n",
    "        # Fixed effects.\n",
    "        beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta, shape=(X_train.shape[1],))\n",
    "        \n",
    "        # Model error\n",
    "        sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "        \n",
    "        # Expected value\n",
    "        mu = alpha[etf_idx_train] + pm.math.dot(X_train, beta)\n",
    "        \n",
    "        # Data likelihood\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_train)\n",
    "        \n",
    "        # Debugging\n",
    "        model_debug = pm.model_to_graphviz(hierarchical_model)\n",
    "        model_debug.render(filename='model_debug', format='png', cleanup=True)\n",
    "\n",
    "        trace = pm.sample(500, tune=200, cores=4, target_accept=0.9, init='adapt_diag')\n",
    "\n",
    "        waic = pm.waic(trace, scale='deviance')\n",
    "        logging.info(f'WAIC: {waic.waic}')\n",
    "\n",
    "    logging.info('Model trained.')\n",
    "    \n",
    "    # Posterior Predictive Checks\n",
    "    with hierarchical_model:\n",
    "        ppc = pm.sample_posterior_predictive(trace, samples=500)\n",
    "    y_pred = ppc['y_obs'].mean(axis=0)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    logging.info(f'Mean Squared Error: {mse}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'An error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ece63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
