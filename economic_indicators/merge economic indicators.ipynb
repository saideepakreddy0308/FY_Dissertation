{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c741544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec75e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\saide\\anaconda3\\envs\\pymc_env\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\saide\\anaconda3\\envs\\pymc_env\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef000c66",
   "metadata": {},
   "source": [
    "### Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b490744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = pd.read_excel(\"csi.xlsx\")\n",
    "unem_rates = pd.read_excel(\"unem_rates.xlsx\")\n",
    "cci = pd.read_excel(\"cci.xlsx\")\n",
    "cli = pd.read_excel(\"cli.xlsx\")\n",
    "bci = pd.read_excel(\"bci.xlsx\")\n",
    "ir = pd.read_excel(\"ir.xlsx\")\n",
    "vix = pd.read_excel(\"vix.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ac8fb",
   "metadata": {},
   "source": [
    "### CSI DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b205533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Month', 'Year', 'Index'], dtype='object')\n",
      "   Month  Year  Index\n",
      "0      1  2018   95.7\n",
      "1      2  2018   99.7\n",
      "2      3  2018  101.4\n",
      "3      4  2018   98.8\n",
      "4      5  2018   98.0\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(csi.columns)\n",
    "\n",
    "# Display the first few rows\n",
    "print(csi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088a404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('csi.xlsx')\n",
    "\n",
    "# Create a datetime column combining Month and Year\n",
    "df['Date'] = pd.to_datetime(df.assign(Day=1).loc[:, ['Year','Month','Day']])\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaaf8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Linear Interpolation for missing values\n",
    "df_daily['Index'] = df_daily['Index'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before saving to get 'Date' as a column\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Remove Month and Year columns\n",
    "df_daily.drop(['Month', 'Year'], axis=1, inplace=True)\n",
    "\n",
    "# Remove the last row from DataFrame\n",
    "df_daily.drop(df_daily.tail(1).index, inplace=True)\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_csi.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adc5d2",
   "metadata": {},
   "source": [
    "### Uemployment Rates Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef56aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('unem_rates.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc990e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saide\\AppData\\Local\\Temp\\ipykernel_28012\\1238086383.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_daily['Value'] = df_daily['Value'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Forward-filling the missing values\n",
    "df_daily['Value'] = df_daily['Value'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f677b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before saving to get 'Date' as a column\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_unem_rates.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f8da5",
   "metadata": {},
   "source": [
    "### CLI Data Transfrom - Spline Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d6ab1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('cli.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9edad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85f38197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN rows before creating a spline object\n",
    "df_not_nan = df_daily.dropna()\n",
    "\n",
    "# Create a UnivariateSpline object\n",
    "x = np.arange(len(df_not_nan))\n",
    "y = df_not_nan['Value'].values\n",
    "spline = UnivariateSpline(x, y)\n",
    "\n",
    "# Use the spline object to interpolate the missing values\n",
    "df_daily_index = np.arange(len(df_daily))\n",
    "df_daily['Value'] = spline(df_daily_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9d8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_cli.xlsx', index=False, columns=['Date', 'Value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b180a8",
   "metadata": {},
   "source": [
    "### CCI DATA TRANSFORM  - Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11910a6",
   "metadata": {},
   "source": [
    "Consumer Confidence Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898bcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('cci.xlsx')\n",
    "\n",
    "# Convert 'TIME' to datetime format, using day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efaf5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2987e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly interpolate the missing values\n",
    "df_daily['Value'] = df_daily['Value'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c355c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_cci.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d0677",
   "metadata": {},
   "source": [
    "### BCI DATA TRANSFROM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33b7d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('bci.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n",
    "\n",
    "\n",
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Drop the NaN rows before creating a spline object\n",
    "df_not_nan = df_daily.dropna()\n",
    "\n",
    "# Create a UnivariateSpline object\n",
    "x = np.arange(len(df_not_nan))\n",
    "y = df_not_nan['Value'].values\n",
    "spline = UnivariateSpline(x, y)\n",
    "\n",
    "# Use the spline object to interpolate the missing values\n",
    "df_daily_index = np.arange(len(df_daily))\n",
    "df_daily['Value'] = spline(df_daily_index)\n",
    "\n",
    "\n",
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_bci.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f074af",
   "metadata": {},
   "source": [
    "### Interest Rates DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d38e73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the existing Excel file\n",
    "df = pd.read_excel('ir.xlsx')\n",
    "\n",
    "# Assuming the 'Date' column is already in datetime format\n",
    "# If not, convert it to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Create a DataFrame with a complete date range\n",
    "complete_date_range = pd.date_range(start='2018-01-01', end='2022-12-31', freq='D')\n",
    "df_full = pd.DataFrame({'Date': complete_date_range})\n",
    "\n",
    "# Merge the two DataFrames on the 'Date' column\n",
    "df_merged = pd.merge(df_full, df, on='Date', how='left')\n",
    "\n",
    "# Apply logarithm to 'Value' to linearize the data\n",
    "df_merged['LogValue'] = np.log(df_merged['Value'])\n",
    "\n",
    "# Linearly interpolate the log-transformed data\n",
    "df_merged['LogValue'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Exponentiate the result to get back to the original scale\n",
    "df_merged['Value'] = np.exp(df_merged['LogValue'])\n",
    "\n",
    "\n",
    "# Save DataFrame back to Excel\n",
    "df_merged.to_excel('transformed_data_ir.xlsx', index=False, columns=['Date', 'Value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58961469",
   "metadata": {},
   "source": [
    "### VIX DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9391c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('vix.xlsx')\n",
    "\n",
    "# Convert the 'DATE' column to string for consistency\n",
    "df['DATE'] = df['DATE'].astype(str)\n",
    "\n",
    "# Function to handle dual date formats\n",
    "def convert_date(date_str):\n",
    "    try:\n",
    "        # First, try with the format '%Y-%d-%m %H:%M:%S'\n",
    "        return pd.to_datetime(date_str, format='%Y-%d-%m %H:%M:%S')\n",
    "    except ValueError:\n",
    "        # If the above fails, use the format '%m-%d-%Y'\n",
    "        return pd.to_datetime(date_str, format='%m-%d-%Y')\n",
    "\n",
    "# Apply the function to the 'DATE' column\n",
    "df['DATE'] = df['DATE'].apply(convert_date)\n",
    "\n",
    "# Convert to desired format: 'DD-MM-YYYY'\n",
    "df['DATE'] = df['DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Save the modified DataFrame\n",
    "df.to_excel('modified_vix.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac71cdcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"16-01-2018-01\" doesn't match format \"%m-%d-%Y-%H\", at position 9. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified_vix.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert 'TIME' to datetime format, using day as 1\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-01\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Sort DataFrame by Date\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"16-01-2018-01\" doesn't match format \"%m-%d-%Y-%H\", at position 9. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('modified_vix.xlsx')\n",
    "\n",
    "# Convert 'TIME' to datetime format, using day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n",
    "\n",
    "\n",
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "\n",
    "# Linearly interpolate the missing values\n",
    "df_daily['Value'] = df_daily['Value'].interpolate(method='linear')\n",
    "\n",
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_vix.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482c6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
