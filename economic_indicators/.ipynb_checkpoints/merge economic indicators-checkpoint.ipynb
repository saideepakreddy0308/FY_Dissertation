{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c741544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec75e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\saide\\anaconda3\\envs\\pymc_env\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\saide\\anaconda3\\envs\\pymc_env\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef000c66",
   "metadata": {},
   "source": [
    "### Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b490744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = pd.read_excel(\"csi.xlsx\")\n",
    "unem_rates = pd.read_excel(\"unem_rates.xlsx\")\n",
    "cci = pd.read_excel(\"cci.xlsx\")\n",
    "cli = pd.read_excel(\"cli.xlsx\")\n",
    "bci = pd.read_excel(\"bci.xlsx\")\n",
    "ir = pd.read_excel(\"ir.xlsx\")\n",
    "vix = pd.read_excel(\"vix.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ac8fb",
   "metadata": {},
   "source": [
    "### CSI DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b205533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Month', 'Year', 'Index'], dtype='object')\n",
      "   Month  Year  Index\n",
      "0      1  2018   95.7\n",
      "1      2  2018   99.7\n",
      "2      3  2018  101.4\n",
      "3      4  2018   98.8\n",
      "4      5  2018   98.0\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(csi.columns)\n",
    "\n",
    "# Display the first few rows\n",
    "print(csi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088a404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('csi.xlsx')\n",
    "\n",
    "# Create a datetime column combining Month and Year\n",
    "df['Date'] = pd.to_datetime(df.assign(Day=1).loc[:, ['Year','Month','Day']])\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaaf8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Linear Interpolation for missing values\n",
    "df_daily['Index'] = df_daily['Index'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before saving to get 'Date' as a column\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Remove Month and Year columns\n",
    "df_daily.drop(['Month', 'Year'], axis=1, inplace=True)\n",
    "\n",
    "# Remove the last row from DataFrame\n",
    "df_daily.drop(df_daily.tail(1).index, inplace=True)\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_csi.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adc5d2",
   "metadata": {},
   "source": [
    "### Uemployment Rates Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef56aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('unem_rates.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc990e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saide\\AppData\\Local\\Temp\\ipykernel_28012\\1238086383.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_daily['Value'] = df_daily['Value'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Forward-filling the missing values\n",
    "df_daily['Value'] = df_daily['Value'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f677b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before saving to get 'Date' as a column\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_unem_rates.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f8da5",
   "metadata": {},
   "source": [
    "### CLI Data Transfrom - Spline Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d6ab1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('cli.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9edad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85f38197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN rows before creating a spline object\n",
    "df_not_nan = df_daily.dropna()\n",
    "\n",
    "# Create a UnivariateSpline object\n",
    "x = np.arange(len(df_not_nan))\n",
    "y = df_not_nan['Value'].values\n",
    "spline = UnivariateSpline(x, y)\n",
    "\n",
    "# Use the spline object to interpolate the missing values\n",
    "df_daily_index = np.arange(len(df_daily))\n",
    "df_daily['Value'] = spline(df_daily_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9d8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_cli.xlsx', index=False, columns=['Date', 'Value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b180a8",
   "metadata": {},
   "source": [
    "### CCI DATA TRANSFORM  - Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11910a6",
   "metadata": {},
   "source": [
    "Consumer Confidence Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898bcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('cci.xlsx')\n",
    "\n",
    "# Convert 'TIME' to datetime format, using day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efaf5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2987e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly interpolate the missing values\n",
    "df_daily['Value'] = df_daily['Value'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c355c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_cci.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d0677",
   "metadata": {},
   "source": [
    "### BCI DATA TRANSFROM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33b7d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('bci.xlsx')\n",
    "\n",
    "# Convert the 'TIME' column to datetime format with day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n",
    "\n",
    "\n",
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "# Drop the NaN rows before creating a spline object\n",
    "df_not_nan = df_daily.dropna()\n",
    "\n",
    "# Create a UnivariateSpline object\n",
    "x = np.arange(len(df_not_nan))\n",
    "y = df_not_nan['Value'].values\n",
    "spline = UnivariateSpline(x, y)\n",
    "\n",
    "# Use the spline object to interpolate the missing values\n",
    "df_daily_index = np.arange(len(df_daily))\n",
    "df_daily['Value'] = spline(df_daily_index)\n",
    "\n",
    "\n",
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_bci.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f074af",
   "metadata": {},
   "source": [
    "### Interest Rates DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d38e73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the existing Excel file\n",
    "df = pd.read_excel('ir.xlsx')\n",
    "\n",
    "# Assuming the 'Date' column is already in datetime format\n",
    "# If not, convert it to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Create a DataFrame with a complete date range\n",
    "complete_date_range = pd.date_range(start='2018-01-01', end='2022-12-31', freq='D')\n",
    "df_full = pd.DataFrame({'Date': complete_date_range})\n",
    "\n",
    "# Merge the two DataFrames on the 'Date' column\n",
    "df_merged = pd.merge(df_full, df, on='Date', how='left')\n",
    "\n",
    "# Apply logarithm to 'Value' to linearize the data\n",
    "df_merged['LogValue'] = np.log(df_merged['Value'])\n",
    "\n",
    "# Linearly interpolate the log-transformed data\n",
    "df_merged['LogValue'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Exponentiate the result to get back to the original scale\n",
    "df_merged['Value'] = np.exp(df_merged['LogValue'])\n",
    "\n",
    "\n",
    "# Save DataFrame back to Excel\n",
    "df_merged.to_excel('transformed_data_ir.xlsx', index=False, columns=['Date', 'Value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58961469",
   "metadata": {},
   "source": [
    "### VIX DATA TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aad4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('vix.xlsx')\n",
    "\n",
    "# Convert the 'DATE' column to string for consistency\n",
    "df['DATE'] = df['DATE'].astype(str)\n",
    "\n",
    "# Function to handle dual date formats\n",
    "def convert_date(date_str):\n",
    "    try:\n",
    "        # First, try with the format '%Y-%d-%m %H:%M:%S'\n",
    "        return pd.to_datetime(date_str, format='%Y-%d-%m %H:%M:%S')\n",
    "    except ValueError:\n",
    "        # If the above fails, use the format '%m-%d-%Y'\n",
    "        return pd.to_datetime(date_str, format='%m-%d-%Y')\n",
    "\n",
    "# Apply the function to the 'DATE' column\n",
    "df['DATE'] = df['DATE'].apply(convert_date)\n",
    "\n",
    "# Convert to desired format: 'DD-MM-YYYY'\n",
    "df['DATE'] = df['DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Save the modified DataFrame\n",
    "df.to_excel('modified_vix.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac71cdcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m df_full \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: complete_date_range})\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Merge the two DataFrames on the 'Date' column\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_full, df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Linearly interpolate the missing values\u001b[39;00m\n\u001b[0;32m     27\u001b[0m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minterpolate(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:169\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    155\u001b[0m         left_df,\n\u001b[0;32m    156\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[0;32m    172\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    173\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    174\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    175\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    176\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    177\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    178\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    179\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    180\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:804\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 804\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1483\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m-> 1483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading Excel file\n",
    "df = pd.read_excel('modified_vix.xlsx')\n",
    "\n",
    "# Convert 'TIME' to datetime format, using day as 1\n",
    "df['Date'] = pd.to_datetime(df['TIME'] + '-01')\n",
    "\n",
    "# Sort DataFrame by Date\n",
    "df = df.sort_values(by=['Date'])\n",
    "\n",
    "\n",
    "# Resampling to daily frequency\n",
    "df.set_index('Date', inplace=True)\n",
    "df_daily = df.resample('D').asfreq()\n",
    "\n",
    "\n",
    "# Linearly interpolate the missing values\n",
    "df_daily['Value'] = df_daily['Value'].interpolate(method='linear')\n",
    "\n",
    "# Reset index before filtering and saving\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "# Filtering data between 01/01/2018 and 31/12/2022\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "df_daily = df_daily[(df_daily['Date'] >= start_date) & (df_daily['Date'] <= end_date)]\n",
    "\n",
    "# Saving DataFrame to Excel\n",
    "df_daily.to_excel('transformed_data_vix.xlsx', index=False, columns=['Date', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482c6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
